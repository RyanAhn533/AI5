from sklearn.datasets import load_wine, load_digits, load_breast_cancer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split

random_state = 5656

# 데이터셋 로드
x1, y1 = load_breast_cancer(return_X_y=True)
x2, y2 = load_digits(return_X_y=True)
x3, y3 = load_wine(return_X_y=True)
data_sets = [(x1, y1, 'Breast Cancer'), (x2, y2, 'Digits'), (x3, y3, 'Wine')]

for x, y, name in data_sets:
    print(f"\n===== {name} Dataset =====")
    x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, random_state=random_state, train_size=0.8)

    # 모델 구성
    model1 = DecisionTreeClassifier(random_state=random_state)
    model2 = RandomForestClassifier(random_state=random_state)
    model3 = GradientBoostingClassifier(random_state=random_state)
    model4 = XGBClassifier(random_state=random_state)

    models = [model1, model2, model3, model4]

    for model in models:
        model.fit(x_train, y_train)
        print(f"\nModel: {model.__class__.__name__}")
        print('Accuracy:', model.score(x_test, y_test))
        print('Feature Importances:', model.feature_importances_)

'''
===== Breast Cancer Dataset =====

Model: DecisionTreeClassifier
Accuracy: 0.9473684210526315
Feature Importances: [0.00000000e+00 5.92622680e-02 0.00000000e+00 0.00000000e+00
 2.89888972e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 2.73947869e-03 2.25563612e-03 8.60022379e-03
 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.09518463e-03
 6.96069094e-01 5.93438015e-04 2.27045908e-02 0.00000000e+00
 9.39068554e-03 0.00000000e+00 0.00000000e+00 1.49557024e-01
 3.78409847e-03 8.95938112e-03]

Model: RandomForestClassifier
Accuracy: 0.9736842105263158
Feature Importances: [0.07427433 0.01975042 0.05520152 0.0577957  0.0060324  0.01201796
 0.04550187 0.09747302 0.0047702  0.00372181 0.01016977 0.00692211
 0.01021379 0.03298594 0.00336294 0.00355485 0.0060862  0.00343957
 0.00357302 0.00625617 0.11808049 0.01857956 0.07477451 0.11710902
 0.00987586 0.01182516 0.03617697 0.13331745 0.01017645 0.00698092]

Model: GradientBoostingClassifier
Accuracy: 0.9736842105263158
Feature Importances: [2.74649211e-04 3.76752252e-02 4.67010531e-04 1.59917389e-03
 3.62922253e-04 1.06281732e-03 4.29801548e-04 2.62029849e-02
 1.72034998e-06 3.27852226e-04 7.37144083e-03 2.17721213e-03
 2.18626832e-03 1.37980720e-02 7.14571971e-04 7.82193438e-04
 2.52148806e-03 2.74710988e-04 2.61274370e-03 1.66169180e-03
 4.15391092e-01 3.31669914e-02 1.99232969e-01 1.15652327e-01
 8.37119516e-03 3.51279410e-04 1.30570279e-02 1.10732260e-01
 1.51409948e-03 2.62078508e-05]

Model: XGBClassifier
Accuracy: 0.9649122807017544
Feature Importances: [8.2005020e-03 9.6085370e-03 1.1464424e-02 1.0828115e-02 7.4933297e-03
 5.5717062e-03 1.2462197e-02 5.7050824e-02 2.6367586e-03 0.0000000e+00
 2.2618117e-02 3.5439476e-03 1.4495853e-02 9.9404678e-03 4.1532451e-03
 5.2815438e-03 4.2108915e-04 6.9155917e-04 2.9639516e-03 1.0604320e-02
 2.5309319e-02 2.5867315e-02 6.0152727e-01 5.5905599e-02 1.2226225e-02
 8.7538799e-03 1.2571316e-02 5.0085381e-02 4.0034880e-03 3.7198458e-03]

===== Digits Dataset =====

Model: DecisionTreeClassifier
Accuracy: 0.8194444444444444
Feature Importances: [0.         0.         0.00306356 0.0140948  0.00204772 0.05489357
 0.         0.         0.         0.01782732 0.01941299 0.00206259
 0.017903   0.01805285 0.00135358 0.         0.         0.00424448
 0.01640498 0.01934281 0.04676698 0.09314564 0.00150275 0.
 0.00153416 0.00356088 0.05562597 0.04173473 0.0445563  0.01071188
 0.01381949 0.         0.         0.05815256 0.02293646 0.
 0.06966007 0.01422046 0.00943079 0.         0.         0.00570355
 0.08182193 0.05872275 0.02055417 0.01033285 0.00252668 0.
 0.         0.         0.00351746 0.00684634 0.00722497 0.01660993
 0.02842023 0.         0.         0.00185634 0.00139225 0.00589887
 0.06205824 0.00153613 0.00691394 0.        ]

Model: RandomForestClassifier
Accuracy: 0.9722222222222222
Feature Importances: [0.00000000e+00 2.29538850e-03 2.20641793e-02 1.13266856e-02
 9.29902790e-03 2.11357870e-02 7.93527564e-03 6.12682904e-04
 1.47220338e-04 9.92165966e-03 2.65066754e-02 7.03032998e-03
 1.55489906e-02 3.18026349e-02 4.88738866e-03 3.36018944e-04
 1.50752717e-04 7.35320965e-03 1.95190143e-02 2.37304230e-02
 2.87587853e-02 5.30971652e-02 8.55257662e-03 5.11500717e-04
 6.13717200e-05 1.50290011e-02 4.16344879e-02 2.61225601e-02
 2.63666620e-02 2.29249393e-02 2.96335943e-02 0.00000000e+00
 0.00000000e+00 3.46125094e-02 2.50036796e-02 2.07308660e-02
 3.97880048e-02 1.77871144e-02 2.15444247e-02 0.00000000e+00
 0.00000000e+00 9.46138840e-03 3.76917723e-02 4.36178220e-02
 1.58812430e-02 1.89898785e-02 2.21639848e-02 5.62806050e-05
 6.32107439e-05 2.39091906e-03 1.72589260e-02 2.30416412e-02
 1.64852415e-02 1.81490164e-02 2.29852332e-02 1.35053220e-03
 2.63187689e-05 2.20801566e-03 2.21713353e-02 1.20468858e-02
 2.52170643e-02 3.22207145e-02 1.88827462e-02 3.87724117e-03]

Model: GradientBoostingClassifier
Accuracy: 0.9694444444444444
Feature Importances: [0.00000000e+00 6.66527667e-04 1.02512167e-02 3.20003274e-03
 2.73008909e-03 6.36982988e-02 4.37947194e-03 3.85490526e-03
 1.39603723e-04 3.30297427e-03 2.22626091e-02 9.38767238e-04
 5.39903540e-03 1.38717890e-02 4.64169400e-03 3.76601829e-05
 3.34444481e-04 2.65056935e-03 7.56523287e-03 3.28048769e-02
 2.12978721e-02 9.19507278e-02 4.90433845e-03 9.48722533e-06
 3.65170759e-05 1.10579075e-03 5.08414365e-02 2.18629555e-02
 3.20348013e-02 2.92447120e-02 1.06015616e-02 0.00000000e+00
 0.00000000e+00 6.97848069e-02 4.10845789e-03 4.63532564e-03
 6.86348912e-02 1.11059715e-02 1.51267574e-02 0.00000000e+00
 0.00000000e+00 7.25815948e-03 8.18634482e-02 7.21425404e-02
 9.41391240e-03 7.09531988e-03 2.59380046e-02 2.97958005e-04
 1.09970169e-06 5.96660008e-04 2.53944562e-03 1.68329727e-02
 7.62966472e-03 1.19557817e-02 3.23064822e-02 9.80788605e-04
 6.88523908e-04 2.13337486e-04 1.18366277e-02 2.18949761e-03
 5.20495240e-02 7.03865957e-03 2.18428693e-02 7.27251296e-03]

Model: XGBClassifier
Accuracy: 0.9777777777777777
Feature Importances: [0.         0.04260222 0.0123057  0.00536235 0.00785006 0.03912581
 0.01336434 0.0056652  0.         0.011911   0.01736444 0.00519692
 0.00786241 0.01130337 0.0173807  0.0024959  0.         0.00757054
 0.00508012 0.03726794 0.01369837 0.04848249 0.01077097 0.
 0.         0.00715246 0.02879473 0.01244789 0.02972469 0.02042216
 0.01443897 0.         0.         0.06721935 0.00483902 0.00480526
 0.06170698 0.01315179 0.02314045 0.         0.         0.01585469
 0.03153732 0.03733504 0.01642033 0.00663471 0.03753383 0.
 0.         0.00749776 0.00389966 0.01362542 0.00599679 0.01293425
 0.03307835 0.01431666 0.         0.00055907 0.00903932 0.00659252
 0.06523845 0.00946691 0.04127167 0.02066259]

===== Wine Dataset =====

Model: DecisionTreeClassifier
Accuracy: 0.9444444444444444
Feature Importances: [0.         0.00503838 0.         0.         0.01632434 0.
 0.04210725 0.         0.         0.13142583 0.         0.33347071
 0.4716335 ]

Model: RandomForestClassifier
Accuracy: 0.9722222222222222
Feature Importances: [0.14015716 0.03346017 0.01229637 0.02838967 0.03729639 0.05285425
 0.11071584 0.01538642 0.01732645 0.15178995 0.09821471 0.12449539
 0.17761724]

Model: GradientBoostingClassifier
Accuracy: 0.9722222222222222
Feature Importances: [3.04902357e-02 3.49693384e-02 1.50533423e-02 3.19468478e-03
 5.65447938e-03 1.38933371e-04 5.89004225e-02 1.83902025e-04
 9.70949709e-04 2.91659320e-01 2.10415856e-03 2.54982172e-01
 3.01698062e-01]

Model: XGBClassifier
Accuracy: 0.9722222222222222
Feature Importances: [0.01622216 0.08208017 0.02668359 0.00534631 0.04227122 0.03786773
 0.06577902 0.00720315 0.00969014 0.18392764 0.00564076 0.3677633
 0.14952475]
'''